# docker-compose.yml

services:
  # Kafka cluster (KRaft mode - single node for learning)
  kafka:
    image: bitnami/kafka:3.9
    container_name: kafka
    ports:
      - "29092:9092"
    environment:
      - KAFKA_CFG_NODE_ID=1
      - KAFKA_CFG_PROCESS_ROLES=broker,controller
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093,PLAINTEXT_HOST://:9094
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:9094
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka:9093
      - KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
      - KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR=1
      - ALLOW_PLAINTEXT_LISTENER=yes
    volumes:
      - kafka_data:/bitnami/kafka
    networks:
      - thrift-network-dev
    healthcheck:
      test:
        ["CMD", "kafka-topics.sh", "--bootstrap-server", "kafka:9092", "--list"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  mongodb:
    image: mongo:8.0
    container_name: mongodb
    environment:
      - MONGO_INITDB_DATABASE=users
    ports:
      - "27017:27017"
    volumes:
      - mongodb_data:/data/db
    networks:
      - thrift-network-dev
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  # mongo-express:
  #   image: mongo-express:latest
  #   container_name: mongo-express
  #   depends_on:
  #     mongodb:
  #       condition: service_healthy
  #   ports:
  #     - "8081:8081"
  #   environment:
  #     ME_CONFIG_MONGODB_URL: mongodb://mongodb:27017/users
  #     ME_CONFIG_MONGODB_ENABLE_ADMIN: "true"
  #   networks:
  #     - thrift-network-dev

  user-rest-spring-service:
    build:
      context: ./user-rest-spring-service
      dockerfile: Dockerfile
    image: hzeroxium/user-rest-spring-service:latest
    container_name: user-rest-spring-service
    env_file:
      - env.common
      - env.user-rest
    volumes:
      # Mount logs directory to host with proper permissions
      - ./logs/user-rest-spring-service:/app/logs:rw
    depends_on:
      user-thrift-server-service:
        condition: service_healthy
      kafka:
        condition: service_healthy
      redis:
        condition: service_healthy
    ports:
      - "28080:8080"
    networks:
      - thrift-network-dev
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=user-rest-spring-service,environment=docker"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/actuator/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  # Loki for log aggregation
  # loki:
  #   image: grafana/loki:3.5
  #   container_name: loki
  #   ports:
  #     - "3100:3100"
  #   volumes:
  #     - ./config/loki/loki-config.yml:/etc/loki/local-config.yaml
  #     - loki_data:/loki
  #   command: -config.file=/etc/loki/local-config.yaml
  #   networks:
  #     - thrift-network-dev
  #   healthcheck:
  #     test:
  #       [
  #         "CMD",
  #         "wget",
  #         "--no-verbose",
  #         "--tries=1",
  #         "--spider",
  #         "http://localhost:3100/ready",
  #       ]
  #     interval: 10s
  #     timeout: 5s
  #     retries: 5
  #     start_period: 30s

  # Grafana for visualization
  # grafana:
  #   image: grafana/grafana:main-ubuntu
  #   container_name: grafana
  #   ports:
  #     - "3000:3000"
  #   environment:
  #     - GF_SECURITY_ADMIN_PASSWORD=admin
  #     - GF_USERS_ALLOW_SIGN_UP=false
  #     - GF_INSTALL_PLUGINS=grafana-piechart-panel
  #     - GF_PATHS_PROVISIONING=/etc/grafana/provisioning
  #     - GF_PATHS_CONFIG=/etc/grafana/grafana.ini
  #   volumes:
  #     - grafana_data:/var/lib/grafana
  #     - ./config/grafana/grafana.ini:/etc/grafana/grafana.ini
  #     - ./config/grafana/grafana-datasources.yml:/etc/grafana/provisioning/datasources/datasources.yml
  #     - ./config/grafana/provisioning/dashboards/dashboard_providers.yml:/etc/grafana/provisioning/dashboards/dashboard_providers.yml
  #     - ./config/grafana/dashboards:/var/lib/grafana/dashboards
  #   depends_on:
  #     prometheus:
  #       condition: service_healthy
  #     loki:
  #       condition: service_healthy
  #   networks:
  #     - thrift-network-dev
  #   healthcheck:
  #     test:
  #       [
  #         "CMD",
  #         "wget",
  #         "--no-verbose",
  #         "--tries=1",
  #         "--spider",
  #         "http://localhost:3000/api/health",
  #       ]
  #     interval: 10s
  #     timeout: 5s
  #     retries: 5
  #     start_period: 30s

  # Prometheus for metrics collection
  # prometheus:
  #   image: prom/prometheus:v3.5.0
  #   container_name: prometheus
  #   ports:
  #     - "9091:9090"
  #   volumes:
  #     - ./config/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
  #     - ./config/prometheus/prometheus-rules.yml:/etc/prometheus/rules/prometheus-rules.yml
  #     - prometheus_data:/prometheus
  #   command:
  #     - "--config.file=/etc/prometheus/prometheus.yml"
  #     - "--storage.tsdb.path=/prometheus"
  #     - "--web.console.libraries=/etc/prometheus/console_libraries"
  #     - "--web.console.templates=/etc/prometheus/consoles"
  #     - "--storage.tsdb.retention.time=200h"
  #     - "--web.enable-lifecycle"
  #     - "--web.enable-admin-api"
  #   networks:
  #     - thrift-network-dev
  #   healthcheck:
  #     test:
  #       [
  #         "CMD",
  #         "wget",
  #         "--no-verbose",
  #         "--tries=1",
  #         "--spider",
  #         "http://localhost:9090/-/healthy",
  #       ]
  #     interval: 10s
  #     timeout: 5s
  #     retries: 5
  #     start_period: 30s

  # cAdvisor for container metrics
  # cadvisor:
  #   image: gcr.io/cadvisor/cadvisor:v0.52.0
  #   container_name: cadvisor
  #   ports:
  #     - "8082:8080"
  #   volumes:
  #     - /:/rootfs:ro
  #     - /var/run:/var/run:ro
  #     - /sys:/sys:ro
  #     - /var/lib/docker/:/var/lib/docker:ro
  #     - /dev/disk/:/dev/disk:ro
  #   privileged: true
  #   devices:
  #     - /dev/kmsg
  #   networks:
  #     - thrift-network-dev
  #   healthcheck:
  #     test:
  #       [
  #         "CMD",
  #         "wget",
  #         "--no-verbose",
  #         "--tries=1",
  #         "--spider",
  #         "http://localhost:8080/healthz",
  #       ]
  #     interval: 10s
  #     timeout: 5s
  #     retries: 5
  #     start_period: 30s

  # Promtail for log collection
  # promtail:
  #   image: grafana/promtail:3.5
  #   container_name: promtail
  #   volumes:
  #     - ./logs:/var/log/apps:ro
  #     - /var/log:/var/log/host:ro
  #     - /var/lib/docker/containers:/var/lib/docker/containers:ro
  #     - ./config/promtail/promtail-config.yml:/etc/promtail/config.yml
  #     - /var/run/docker.sock:/var/run/docker.sock:ro
  #   command: -config.file=/etc/promtail/config.yml
  #   networks:
  #     - thrift-network-dev
  #   depends_on:
  #     - loki

  # Schema Registry removed - using Thrift for schema management

  # kafbat-ui:
  #   image: ghcr.io/kafbat/kafka-ui:main
  #   container_name: kafbat-ui
  #   ports:
  #     - "8084:8080"
  #   environment:
  #     - DYNAMIC_CONFIG_ENABLED=true
  #     - KAFKA_CLUSTERS_0_NAME=local
  #     - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:9092

  #   depends_on:
  #     kafka:
  #       condition: service_healthy
  #   networks:
  #     - thrift-network-dev

  redis:
    image: redis:latest
    container_name: redis
    ports:
      - "26379:6379"
    networks:
      - thrift-network-dev
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  user-watcher-service:
    build:
      context: ./user-watcher-service
      dockerfile: Dockerfile
    image: hzeroxium/user-watcher-service:latest
    container_name: user-watcher-service
    env_file:
      - env.common
      - env.user-watcher
    ports:
      - "28086:8080"
    volumes:
      - ./logs/user-watcher-service:/app/logs:rw
    depends_on:
      mongodb:
        condition: service_healthy
      kafka:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - thrift-network-dev
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=user-watcher-service,environment=docker"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/actuator/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  user-thrift-server-service:
    build:
      context: ./user-thrift-server-service
      dockerfile: Dockerfile
    image: hzeroxium/user-thrift-server-service:latest
    container_name: user-thrift-server-service
    env_file:
      - env.common
      - env.user-thrift
    ports:
      - "28085:8080"
      - "29090:9090"
    volumes:
      - ./logs/user-thrift-server-service:/app/logs:rw
    depends_on:
      kafka:
        condition: service_healthy
      user-watcher-service:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - thrift-network-dev
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=user-thrift-server-service,environment=docker"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/actuator/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

volumes:
  mongodb_data:
  kafka_data:
  loki_data:
  grafana_data:
  prometheus_data:
  redis_data:
networks:
  thrift-network-dev:
    driver: bridge
